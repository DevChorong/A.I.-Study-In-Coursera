{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic-Supervised-Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevChorong/A.I.-Study-In-Coursera/blob/master/Basic_Supervised_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dapaYZwilpuO",
        "colab_type": "text"
      },
      "source": [
        "# Basic Supervised Learning\n",
        "******\n",
        "This Note is for 'Basic Level Supervised Learning'\n",
        "\n",
        "we just know about the grammer that some of scikit-learn that include about Decision-Tree\n",
        "\n",
        "## [1] Decision Tree \n",
        "\n",
        "### # INDEX\n",
        "> 1. Call Scikit-learn\n",
        "> 2. make some Training Dataset / Test Dataset\n",
        "> 3. gatering **Features** and **Labels**\n",
        "> 4. Training the **Classifier** several time to enough \n",
        "> 5. Predict the Test Dataset\n",
        "> 6. make Confidence ratio\n",
        "\n",
        "\n",
        "### # 1. Call Scikit-learn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk5VIuI8sEfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#========[ 1 ]=========================#\n",
        "from sklearn import tree # Call Decision Tree from Scikit-Learn lib ( call it sklearn ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A4d0jC3s6Pn",
        "colab_type": "text"
      },
      "source": [
        "### # 2. make some Training Dataset / Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_dabQKBs_E1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#========[ 1 ]=========================#\n",
        "from sklearn import tree\n",
        "#========[ 2 ]=========================#\n",
        "from sklearn.datasets import load_iris # we use iris dataset that one of built-in default dataset\n",
        "\n",
        "iris_data = load_iris() # call iris dataset to code with use \"load_iris()\" function\n",
        "\n",
        "train = iris_data # we traing the data for iris dataset\n",
        "\n",
        "test = [[5.0,\t3.6,\t1.4,\t0.2], [6.1,\t3.0, 4.7, 1.5], [7.7, 2.8, 6.7, 2.4]] # the Test Data [ setosa(0), versicolor(1), virginica(2)]\n",
        "test_answer = [0,1,2]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ahmr8-UvbJw",
        "colab_type": "text"
      },
      "source": [
        "### # 3. gatering **Features** and **Labels**\n",
        "before we gatering Features and Labels\n",
        "we just know about what kinds of Features that dataset has"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjrq5wyrvvbj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "46b3ed25-a5fb-4625-e32e-e8c0c442059e"
      },
      "source": [
        "from sklearn import tree\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "print(\"Features : {0}\".format(iris_data['feature_names']))\n",
        "\n",
        "print(\"First data : {0}\".format(iris_data['data'][:1]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features : ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "First data : [[5.1 3.5 1.4 0.2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pc_T9AfwkxY",
        "colab_type": "text"
      },
      "source": [
        "that we know about what kinds of Features that dataset has\n",
        "> 1. sepal length (cm)\n",
        "> 2. sepal width (cm)\n",
        "> 3. petal length (cm)\n",
        "> 4. petal width (cm)\n",
        "\n",
        "so in first Data we can decode that data like this\n",
        "\n",
        "**\"[1] : Sepal length 5.1cm, Sepal width 3.5cm, Petal length 1.4cm, Petal width 0.2cm\"**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifkoh9PaxzFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#========[ 1 ]=========================#\n",
        "from sklearn import tree\n",
        "\n",
        "#========[ 2 ]=========================#\n",
        "from sklearn.datasets import load_iris # we use iris dataset that one of built-in default dataset\n",
        "\n",
        "iris_data = load_iris() # call iris dataset to code for use \"load_iris()\" function\n",
        "\n",
        "train = iris_data # we traing the data for iris dataset\n",
        "\n",
        "test = [[5.0,\t3.6,\t1.4,\t0.2], [6.1,\t3.0, 4.7, 1.5], [7.7, 2.8, 6.7, 2.4]] # the Test Data [ setosa(0), versicolor(1), virginica(2)]\n",
        "test_answer = [0,1,2]\n",
        "\n",
        "#========[ 3 ]=========================#\n",
        "\n",
        "features = iris_data['data'][:-1] # 'feature' would be 'all of Data'\n",
        "labels = iris_data['target'][:-1] # 'answer(Label)' is would be 'target'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRy7aBtBxvY0",
        "colab_type": "text"
      },
      "source": [
        "### # 4. Training the **Classifier** several time to enough "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-bego3iyaKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#========[ 1 ]=========================#\n",
        "from sklearn import tree\n",
        "\n",
        "#========[ 2 ]=========================#\n",
        "from sklearn.datasets import load_iris # we use iris dataset that one of built-in default dataset\n",
        "\n",
        "iris_data = load_iris() # call iris dataset to code for use \"load_iris()\" function\n",
        "\n",
        "train = iris_data # we traing the data for iris dataset\n",
        "\n",
        "test = [[5.0,\t3.6,\t1.4,\t0.2], [6.1,\t3.0, 4.7, 1.5], [7.7, 2.8, 6.7, 2.4]] # the Test Data [ setosa(0), versicolor(1), virginica(2)]\n",
        "test_answer = [0,1,2]\n",
        "\n",
        "#========[ 3 ]=========================#\n",
        "features = iris_data['data'][:-1] # 'feature' would be 'all of Data'\n",
        "labels = iris_data['target'][:-1] # 'answer(Label)' is would be 'target'\n",
        "\n",
        "#========[ 4 ]=========================#\n",
        "clf = tree.DecisionTreeClassifier() # we make Classifier(clf) for use \"tree.DecisionTreeClassifier()\" function\n",
        "clf = clf.fit(features, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnKi972ozGx6",
        "colab_type": "text"
      },
      "source": [
        "### # 5. Predict the Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrp-vYhSzHB6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "17b52b06-ed6d-466a-8cb8-92a07481125b"
      },
      "source": [
        "#========[ 1 ]=========================#\n",
        "from sklearn import tree\n",
        "\n",
        "#========[ 2 ]=========================#\n",
        "from sklearn.datasets import load_iris # we use iris dataset that one of built-in default dataset\n",
        "\n",
        "iris_data = load_iris() # call iris dataset to code for use \"load_iris()\" function\n",
        "\n",
        "train = iris_data # we traing the data for iris dataset\n",
        "\n",
        "test = [[5.0,\t3.6,\t1.4,\t0.2], [6.1,\t3.0, 4.7, 1.5], [7.7, 2.8, 6.7, 2.4]] # the Test Data [ setosa(0), versicolor(1), virginica(2)]\n",
        "test_answer = [0,1,2]\n",
        "\n",
        "#========[ 3 ]=========================#\n",
        "features = iris_data['data'][:-1] # 'feature' would be 'all of Data'\n",
        "labels = iris_data['target'][:-1] # 'answer(Label)' is would be 'target'\n",
        "\n",
        "#========[ 4 ]=========================#\n",
        "clf = tree.DecisionTreeClassifier() # we make Classifier(clf) for use \"tree.DecisionTreeClassifier()\" function\n",
        "clf = clf.fit(features, labels)\n",
        "\n",
        "#========[ 5 ]=========================#\n",
        "perdict = clf.predict(test)\n",
        "\n",
        "\n",
        "#========[ 6 ]=========================#\n",
        "for i in range(3):\n",
        "  print(\"Answer {0} // perdict {1}\".format(test_answer[i], perdict[i]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Answer 0 // perdict 0\n",
            "Answer 1 // perdict 1\n",
            "Answer 2 // perdict 2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}